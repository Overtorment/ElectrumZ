#!/usr/bin/env bun
// Copyright (c) 2024-present The Bitcoin Core developers
// Distributed under the MIT software license, see the accompanying
// file COPYING or http://www.opensource.org/licenses/mit-license.php.
/** Tool to convert a compact-serialized UTXO set to a SQLite3 database.

The input UTXO set can be generated by Bitcoin Core with the `dumptxoutset` RPC:
$ bitcoin-cli dumptxoutset ~/utxos.dat latest

The created database contains a table `utxos` with the following schema:
(outpoint BLOB, value INT, height INT, scripthash BLOB)
Where `outpoint` is 36 bytes: 32-byte prevout hash concatenated with 4-byte little-endian prevout index.
*/

import { Database } from "bun:sqlite";
import { parseArgs } from "util";
import { existsSync } from "fs";
import { computeScripthash } from "./scripthash";

const UTXO_DUMP_MAGIC = Buffer.from([0x75, 0x74, 0x78, 0x6f, 0xff]); // 'utxo\xff'
const UTXO_DUMP_VERSION = 2;
const NET_MAGIC_BYTES: Record<string, string> = {
  "f9beb4d9": "Mainnet",
  "0a03cf40": "Signet",
  "0b110907": "Testnet3",
  "1c163f28": "Testnet4",
  "fabfb5da": "Regtest",
};

class StreamingBinaryReader {
  private file: Blob;
  private position: number = 0;
  private buffer: Buffer = Buffer.alloc(0);
  private bufferStart: number = 0;
  private readonly bufferSize: number = 64 * 1024;

  constructor(file: Blob) {
    this.file = file;
  }

  private async ensureBuffer(minBytes: number): Promise<void> {
    const relPos = this.position - this.bufferStart;
    const available = this.buffer.length - relPos;
    if (available >= minBytes) return;

    const readStart = this.position;
    const readSize = Math.max(this.bufferSize, minBytes);
    const slice = (this.file as any).slice(readStart, readStart + readSize);
    const ab = await slice.arrayBuffer();
    this.buffer = Buffer.from(ab);
    this.bufferStart = readStart;
  }

  async read(length: number): Promise<Buffer> {
    await this.ensureBuffer(length);
    const relPos = this.position - this.bufferStart;
    if (relPos + length > this.buffer.length) throw new Error("Unexpected end of file");
    const out = this.buffer.subarray(relPos, relPos + length);
    this.position += length;
    return out;
  }

  async readUInt8(): Promise<number> {
    const b = await this.read(1);
    return b[0];
  }

  async readUInt16LE(): Promise<number> {
    const b = await this.read(2);
    return b.readUInt16LE(0);
  }

  async readUInt32LE(): Promise<number> {
    const b = await this.read(4);
    return b.readUInt32LE(0);
  }

  async readBigUInt64LE(): Promise<bigint> {
    const b = await this.read(8);
    return b.readBigUInt64LE(0);
  }

  async isAtEnd(): Promise<boolean> {
    return this.position >= (this.file as any).size;
  }
}

async function readVarInt(reader: StreamingBinaryReader): Promise<number> {
  let n = 0;
  while (true) {
    const dat = await reader.readUInt8();
    n = (n << 7) | (dat & 0x7f);
    if ((dat & 0x80) > 0) {
      n += 1;
    } else {
      return n;
    }
  }
}

async function readCompactSize(reader: StreamingBinaryReader): Promise<number> {
  let n = await reader.readUInt8();
  if (n === 253) {
    n = await reader.readUInt16LE();
  } else if (n === 254) {
    n = await reader.readUInt32LE();
  } else if (n === 255) {
    n = Number(await reader.readBigUInt64LE());
  }
  return n;
}

function decompressAmount(x: number): number {
  if (x === 0) return 0;
  x -= 1;
  const e = x % 10;
  x = Math.floor(x / 10);
  let n = 0;
  if (e < 9) {
    const d = (x % 9) + 1;
    x = Math.floor(x / 9);
    n = x * 10 + d;
  } else {
    n = x + 1;
  }
  for (let i = 0; i < e; i++) n *= 10;
  return n;
}

function modPow(base: bigint, exponent: bigint, modulus: bigint): bigint {
  if (modulus === 1n) return 0n;
  let result = 1n;
  base = base % modulus;
  while (exponent > 0n) {
    if (exponent % 2n === 1n) result = (result * base) % modulus;
    exponent >>= 1n;
    base = (base * base) % modulus;
  }
  return result;
}

function decompressPubkey(compressedPubkey: Buffer): Buffer {
  const P = 2n ** 256n - 2n ** 32n - 977n;
  if (compressedPubkey.length !== 33 || (compressedPubkey[0] !== 2 && compressedPubkey[0] !== 3)) {
    throw new Error(`Invalid compressed pubkey: ${compressedPubkey.toString("hex")}`);
  }
  const x = BigInt("0x" + compressedPubkey.subarray(1).toString("hex"));
  const rhs = (x ** 3n + 7n) % P;
  let y = modPow(rhs, (P + 1n) / 4n, P);
  if (modPow(y, 2n, P) !== rhs) throw new Error(`Pubkey is not on curve (${compressedPubkey.toString("hex")})`);
  const tagIsOdd = compressedPubkey[0] === 3;
  const yIsOdd = (y & 1n) === 1n;
  if (tagIsOdd !== yIsOdd) y = P - y;
  const xBytes = Buffer.from(x.toString(16).padStart(64, "0"), "hex");
  const yBytes = Buffer.from(y.toString(16).padStart(64, "0"), "hex");
  return Buffer.concat([Buffer.from([4]), xBytes, yBytes]);
}

async function decompressScript(reader: StreamingBinaryReader): Promise<Buffer> {
  const size = await readVarInt(reader);
  if (size === 0) {
    return Buffer.concat([Buffer.from([0x76, 0xa9, 20]), await reader.read(20), Buffer.from([0x88, 0xac])]);
  } else if (size === 1) {
    return Buffer.concat([Buffer.from([0xa9, 20]), await reader.read(20), Buffer.from([0x87])]);
  } else if (size === 2 || size === 3) {
    return Buffer.concat([Buffer.from([33, size]), await reader.read(32), Buffer.from([0xac])]);
  } else if (size === 4 || size === 5) {
    const compressed = Buffer.concat([Buffer.from([size - 2]), await reader.read(32)]);
    return Buffer.concat([Buffer.from([65]), decompressPubkey(compressed), Buffer.from([0xac])]);
  } else {
    const scriptSize = size - 6;
    if (scriptSize > 10000) throw new Error(`too long script with size ${scriptSize}`);
    return reader.read(scriptSize);
  }
}

async function main(): Promise<void> {
  const args = parseArgs({
    args: Bun.argv.slice(2),
    options: { verbose: { type: "boolean", short: "v", default: false } },
    allowPositionals: true,
  });

  if (args.positionals.length !== 2) {
    console.error("Error: Please provide exactly two arguments: <infile> <outfile>");
    process.exit(1);
  }

  const [infile, outfile] = args.positionals as [string, string];

  if (!existsSync(infile)) {
    console.error(`Error: provided input file '${infile}' doesn't exist.`);
    process.exit(1);
  }
  if (existsSync(outfile)) {
    console.error(`Error: provided output file '${outfile}' already exists.`);
    process.exit(1);
  }

  const db = new Database(outfile);
  db.exec("CREATE TABLE utxos(outpoint BLOB, value INT, height INT, scripthash BLOB, CHECK(length(outpoint) = 36), CHECK(length(scripthash) = 32))");
  // db.exec("CREATE INDEX idx_utxos_scripthash ON utxos(scripthash)");

  const file = Bun.file(infile);
  const reader = new StreamingBinaryReader(file);

  const magicBytes = await reader.read(5);
  const version = await reader.readUInt16LE();
  const networkMagic = await reader.read(4);
  const blockHash = await reader.read(32);
  const numUtxos = Number(await reader.readBigUInt64LE());

  if (!magicBytes.equals(UTXO_DUMP_MAGIC)) {
    console.error(`Error: provided input file '${infile}' is not an UTXO dump.`);
    process.exit(1);
  }
  if (version !== UTXO_DUMP_VERSION) {
    console.error(
      `Error: provided input file '${infile}' has unknown UTXO dump version ${version} (only version ${UTXO_DUMP_VERSION} supported)`
    );
    process.exit(1);
  }

  const networkString = NET_MAGIC_BYTES[networkMagic.toString("hex")] ?? `unknown network (${networkMagic.toString("hex")})`;
  console.log(
    `UTXO Snapshot for ${networkString} at block hash ${Buffer.from(blockHash).reverse().toString("hex")}, contains ${numUtxos} utxos`
  );

  const startTime = Date.now();
  const writeBatch: Array<[Buffer, number, number, Buffer]> = [];
  let coinsPerHashLeft = 0;
  let prevoutHashBuf: Buffer = Buffer.alloc(0);
  let maxHeight = 0;

  const insertStmt = db.prepare("INSERT INTO utxos VALUES(?, ?, ?, ?)");
  const insertMany = db.transaction((rows: Array<[Buffer, number, number, Buffer]>) => {
    for (const r of rows) insertStmt.run(...r);
  });

  for (let coinIdx = 1; coinIdx <= numUtxos; coinIdx++) {
    if (coinsPerHashLeft === 0) {
      const hashBuf = await reader.read(32);
      prevoutHashBuf = Buffer.from(hashBuf).reverse();
      coinsPerHashLeft = await readCompactSize(reader);
    }
    const prevoutIndex = await readCompactSize(reader);

    const code = await readVarInt(reader);
    const height = code >> 1;
    const amount = decompressAmount(await readVarInt(reader));
    const script = await decompressScript(reader);
    const scripthash = computeScripthash(script);

    const indexBuf = Buffer.allocUnsafe(4);
    indexBuf.writeUInt32LE(prevoutIndex, 0);
    const outpointBuf = Buffer.concat([prevoutHashBuf, indexBuf]);
    writeBatch.push([outpointBuf, amount, height, scripthash]);
    if (height > maxHeight) maxHeight = height;
    coinsPerHashLeft -= 1;

    if (args.values.verbose) {
      const prevoutHashHex = prevoutHashBuf.toString("hex");
      console.log(`Coin ${coinIdx}/${numUtxos}:`);
      console.log(`    prevout = ${prevoutHashHex}:${prevoutIndex}`);
      console.log(`    amount = ${amount}, height = ${height}`);
      console.log(`    scripthash = ${scripthash.toString("hex")}\n`);
    }

    if (coinIdx % (16 * 1024) === 0 || coinIdx === numUtxos) {
      insertMany(writeBatch);
      writeBatch.length = 0;
    }

    if (coinIdx % (1024 * 1024) === 0) {
      const elapsed = (Date.now() - startTime) / 1000;
      const progress = coinIdx / numUtxos;
      const etaMinutes = progress > 0 ? (elapsed * (1 - progress) / progress) / 60 : 0;
      console.log(
        `${coinIdx} coins converted [${(progress * 100).toFixed(2)}%], ${elapsed.toFixed(3)}s passed since start, ETA ${etaMinutes.toFixed(2)} min`
      );
    }
  }

  db.close();
  console.log(`TOTAL: ${numUtxos} coins written to ${outfile}, snapshot height is ${maxHeight}.`);

  if (!(await reader.isAtEnd())) {
    console.log(`WARNING: input file ${infile} has not reached EOF yet!`);
    process.exit(1);
  }
}

if (import.meta.main) {
  main().catch((e) => {
    console.error("Error:", (e as Error).message);
    process.exit(1);
  });
}


